---
title: "Databases"
author: ["Kirill & Nicolas", "cynkra GmbH"]
date: "March 15, 2022"
output:
  cynkradown::cynkra_slides:
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
      ratio: "16:9"
    seal: true
lang: english
font: frutiger
wide: false
colorlinks: false
logo: true
---

<style type="text/css">
.pull-left {
  margin-top: -25px;
}
.pull-right {
  margin-top: -25px;
}
.remark-code {
    font-size: 14px;
}
.font17 {
    font-size: 17px;
}
.font14 {
    font-size: 14px;
}
</style>


```{r databases-2-1, include = FALSE}
knitr::opts_chunk$set(cache = TRUE, comment = "")

library(tidyverse)
library(DBI)
library(dm)

options(width = 68)

options(pillar.bold = TRUE)
options(cli.num_colors = 256)

fansi::set_knit_hooks(knitr::knit_hooks, c("output", "message", "warning", "error"))
```

```{r databases-2-2, results='hide', message=FALSE, cache = FALSE, include = FALSE}
con_duckdb <- dbConnect(duckdb::duckdb())
con_duckdb
```

```{r databases-2-3, cache = FALSE, include = FALSE}
dm::copy_dm_to(
  con_duckdb,
  dm::dm_pixarfilms(),
  set_key_constraints = FALSE,
  temporary = FALSE
)
```

```{r databases-2-4, cache = FALSE, include = FALSE}
pixar_films <- tbl(con_duckdb, "pixar_films")
pixar_films
```

```{r databases-2-5, cache = FALSE, include = FALSE}
con_sqlite <- DBI::dbConnect(RSQLite::SQLite(), extended_types = TRUE)
dm::copy_dm_to(
  con_sqlite,
  dm::dm_pixarfilms(),
  set_key_constraints = FALSE,
  temporary = FALSE
)
```

```{r databases-2-6, cache = FALSE, include = FALSE}
pixar_films_sqlite <- tbl(con_sqlite, "pixar_films")
pixar_films_sqlite
```

---

# Schedule

Extract ⇨ Transform ⇨ Load ⇨ Consume

.pull-left[
## One table

- Read whole tables
- Let the database do the heavy lifting
- Basic ETL for one table
- Subtle issues to watch out for
]

.pull-right[
## Multiple tables

- **Joins**
- The {dm} package
- A bit of theory
- Playing the whole game
]

## Bonus: Bring your own data + questions

---

background-image: url("images/21.webp")
background-size: 40%
background-position: 100% 100%

# Joins

.pull-left[
- Usage
- Join sources
- Mounting

Script: `databases_21.R`

```{r databases-2-7 }
library(tidyverse)
```
]

---

background-image: url("images/21-frame.webp")
background-size: 40%
background-position: 100% 100%

# Joins

.pull-left[
- Usage
- Join sources
- Mounting

Script: `databases_21.R`

```{r databases-2-8 }
library(tidyverse)
```
]

---

# A second table

.pull-left[
```{r databases-2-9, cache = FALSE}
academy <- tbl(con_duckdb, "academy")
academy_sqlite <- tbl(con_sqlite, "academy")

academy %>%
  count(status)
```
]

.pull-right[
```{r databases-2-10 }
academy
```
]

---

# Left join

The most frequent kind of join.

.pull-left[
## Unsafe

```{r databases-2-11 }
academy %>%
  left_join(pixar_films)
```
]

.pull-right[
## Better

```{r databases-2-12 }
academy %>%
  left_join(pixar_films, by = "film")
```
]

---

# Left join

Computed on the database, original data unchanged.

```{r databases-2-13 }
academy %>%
  left_join(pixar_films, by = "film") %>%
  show_query()
```

---

# Join with preparation

The right-hand side in the join should come from a variable.

.pull-left[
## Prepare RHS

```{r databases-2-14 }
academy_won <-
  academy %>%
  filter(status == "Won") %>%
  count(film, name = "n_won")
academy_won
```
]


.pull-right[
```{r databases-2-15 }
pixar_films %>%
  left_join(academy_won, by = "film")
```
]

---

# Join with postprocessing

.pull-left[
## Raw result

```{r databases-2-16 }
pixar_films %>%
  left_join(academy_won, by = "film") %>%
  arrange(release_date)
```
]


.pull-right[
## After postprocessing

```{r databases-2-17 }
pixar_films %>%
  left_join(academy_won, by = "film") %>%
  mutate(n_won = coalesce(n_won, 0L)) %>%
  arrange(release_date)
```
]

---

# Join with processing

Computed on the database, original data unchanged.

```{r databases-2-18 }
pixar_films %>%
  left_join(academy_won, by = "film") %>%
  mutate(n_won = coalesce(n_won, 0L)) %>%
  arrange(release_date) %>%
  show_query()
```

---

# Tables must be on the same source

Use `copy = TRUE` to enforce, the result is a lazy table if the LHS is a lazy table.

.pull-left[
## Bad

```{r databases-2-19 }
try(
  academy %>%
    left_join(pixar_films_sqlite, by = "film")
)
```
]

.pull-right[
## Not too bad

```{r databases-2-20 }
academy %>%
  left_join(pixar_films_sqlite, by = "film", copy = TRUE)
```
]

---

# Copying is expensive!

A temporary table is created on the LHS database.
If the RHS comes from a different database, results are temporarily loaded into the local session!

```{r databases-2-21 }
academy %>%
  left_join(pixar_films_sqlite, by = "film", copy = TRUE) %>%
  show_query()
```

---

# Joining data frames with lazy tables

The result is a data frame too.

.pull-left[
## Bad

```{r databases-2-22 }
try(
  pixarfilms::academy %>%
    left_join(pixar_films, by = "film")
)
```
]

.pull-right[
## Could be worse

```{r databases-2-23 }
pixarfilms::academy %>%
  left_join(pixar_films, by = "film", copy = TRUE)
```
]

---

# DuckDB: register data frames as database tables

Temporarily use a local data frame as a table.
Also works for Arrow datasets via `duckdb::duckdb_register_arrow()`.

.pull-left[
## Register and access

```{r databases-2-24 }
duckdb::duckdb_register(
  con_duckdb,
  "academy_small",
  pixarfilms::academy[1:3, ]
)

academy_small <- tbl(con_duckdb, "academy_small")
academy_small
```
]

.pull-right[
## Use

```{r databases-2-25 }
academy_small %>%
  left_join(pixar_films, by = "film")
```
]

---

# DuckDB: Performance comparison

Baseline: Data frames.

.pull-left[
```{r databases-2-26 }
nrow(nycflights13::flights)
```
]

.pull-right[
```{r databases-2-27 }
system.time(
  nycflights13::flights %>%
    count(year, month, day)
)
```
]

---

# DuckDB: Performance comparison

With registration.

.pull-left[
```{r databases-2-28 }
system.time(duckdb::duckdb_register(
  con_duckdb,
  "flights",
  nycflights13::flights
))

flights_register <- tbl(con_duckdb, "flights")
flights_register %>%
  count()
```
]

.pull-right[
```{r databases-2-29 }
system.time(
  flights_register %>%
    count(year, month, day) %>%
    collect()
)
```
]

---

# DuckDB: Performance comparison

With copy.

.pull-left[
```{r databases-2-30 }
system.time(
  flights_copy <- copy_to(con_duckdb, nycflights13::flights)
)

flights_copy %>%
  count()
```
]

.pull-right[
```{r databases-2-31 }
system.time(
  flights_copy %>%
    count(year, month, day) %>%
    collect()
)
```
]

---

# ETL, revisited

Insert a second table into our database.

```{r databases-2-32 }
db_path <- fs::path_abs("pixar.duckdb")
con <- DBI::dbConnect(duckdb::duckdb(dbdir = db_path))
DBI::dbWriteTable(con, "academy", pixarfilms::academy, overwrite = TRUE)
DBI::dbExecute(con, "CREATE UNIQUE INDEX academy_pk ON academy (film, award_type)")
DBI::dbExecute(con, "CREATE INDEX academy_fk ON academy (film)")
DBI::dbDisconnect(con)
```

---

background-image: url("images/21-frame.webp")
background-size: 40%
background-position: 100% 100%

# Joins: Exercises 1

.pull-left[
1. How many rows does the join between `academy` and `pixar_films` contain?
   Try to find out without loading all the data into memory. Explain.
2. Which films are not yet listed in the `academy` table? What does the
   resulting SQL query look like?
   - Hint: Use `anti_join()`
]

---

background-image: url("images/21-frame.webp")
background-size: 40%
background-position: 100% 100%

# Joins: Exercises 2

.pull-left[
3. Transform `academy` into a wide table so that there is at most one row
   per film. Join the resulting table with the `pixar_films` table.
   - Hint: Use `pivot_wider()`, `spread()`, `dcast()`, ... . You need to
     compute locally, because these functions don't work on the database.
]

.pull-right[
4. Plot a bar chart with the number of awards won and nominated per year.
   Compute as much as possible on the database.
   - Hint: "Long form" or "wide form"?
]

---

# Schedule

Extract ⇨ Transform ⇨ Load ⇨ Consume

.pull-left[
## One table

- Read whole tables
- Let the database do the heavy lifting
- Basic ETL for one table
- Subtle issues to watch out for
]

.pull-right[
## Multiple tables

- Joins
- **The {dm} package**
- A bit of theory
- Playing the whole game
]

## Bonus: Bring your own data + questions

---

background-image: url("images/22.webp")
background-size: 40%
background-position: 100% 100%

# Data models

.pull-left[
- Compound object for multiple tables
- Features

Script: `databases_22.R`

```{r databases-2-33 }
library(tidyverse)
```
]

---

background-image: url("images/22-frame.webp")
background-size: 40%
background-position: 100% 100%

# Data models

.pull-left[
- Compound object for multiple tables
- Features

Script: `databases_22.R`

```{r databases-2-34 }
library(tidyverse)
```
]

---

# Schedule

Extract ⇨ Transform ⇨ Load ⇨ Consume

.pull-left[
## One table

- Read whole tables
- Let the database do the heavy lifting
- Basic ETL for one table
- Subtle issues to watch out for
]

.pull-right[
## Multiple tables

- Joins
- The {dm} package
- **A bit of theory**
- Playing the whole game
]

## Bonus: Bring your own data + questions

---

background-image: url("images/23.webp")
background-size: 40%
background-position: 100% 100%

# Data models

.pull-left[
- Keys, relationships, constraints
- Zooming

Script: `databases_23.R`

```{r databases-2-35 }
library(tidyverse)
```
]

---

background-image: url("images/23-frame.webp")
background-size: 40%
background-position: 100% 100%

# Data models

.pull-left[
- Keys, relationships, constraints
- Zooming

Script: `databases_23.R`

```{r databases-2-36 }
library(tidyverse)
```
]

---

# Schedule

Extract ⇨ Transform ⇨ Load ⇨ Consume

.pull-left[
## One table

- Read whole tables
- Let the database do the heavy lifting
- Basic ETL for one table
- Subtle issues to watch out for
]

.pull-right[
## Multiple tables

- Joins
- The {dm} package
- A bit of theory
- **Playing the whole game**
]

## Bonus: Bring your own data + questions

---

background-image: url("images/24.webp")
background-size: 40%
background-position: 100% 100%

# The whole game

.pull-left[
- Build a local data model
- Copy it to the database
- Consume it

Script: `databases_24.R`

```{r databases-2-37 }
library(tidyverse)
```
]

---

background-image: url("images/24-frame.webp")
background-size: 40%
background-position: 100% 100%

# The whole game

.pull-left[
- Build a local data model
- Copy it to the database
- Consume it

Script: `databases_24.R`

```{r databases-2-38 }
library(tidyverse)
```
]

---

# Recap

<table>
<tr>
<td rowspan=2>
<img src="images/11-frame.webp" width="200px" />
</td>
<td><img src="images/12-frame.webp" width="200px" /></td>
<td><img src="images/12_2-frame.webp" width="200px" /></td>
<td><img src="images/13-frame.webp" width="200px" /></td>
<td><img src="images/14-frame.webp" width="200px" /></td>
</tr>
<tr style="background:transparent">
<td><img src="images/21-frame.webp" width="200px" /></td>
<td><img src="images/22-frame.webp" width="200px" /></td>
<td><img src="images/23-frame.webp" width="200px" /></td>
<td><img src="images/24-frame.webp" width="200px" /></td>
</tr>
</table>

---

# Schedule

Extract ⇨ Transform ⇨ Load ⇨ Consume

.pull-left[
## One table

- Read whole tables
- Let the database do the heavy lifting
- Basic ETL for one table
- Subtle issues to watch out for
]

.pull-right[
## Multiple tables

- Joins
- The {dm} package
- A bit of theory
- Playing the whole game
]

## Bonus: Bring your own data + questions
